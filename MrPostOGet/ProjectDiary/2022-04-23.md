Det här, tillsammans med, MrBoboSockets, är några av dem tidigaste projekten jag gjort, och har nog haft mest rewrites och refactors av något annat, och varje gång jag kommer tillbaka till det inser jag,
att det finns ännu mer att göra. Det finns väldigt lite fel hantering för SEGFAULT typ av errors, och det finns en väldigt technical debt från massa gammal hemsida kod. När jag skulle fixa 
det felaktiga sättet att parsa search parameters från urlen insåg jag på hur många ställen som jag inte riktigt kollar efter fel, och framförallt, jag vet fortfarande inte hur HTTPServer
kan ta flera requests på raken...

Som det verkar fungera nu kallas GetNextChunkData i en loop, men problemet är, är att denna funktion är båda ansvarig för att ta hand om att ta emot en ny request om den kommer samt extrahera 
gammal request data. Detta är i sig ganskla jank för att det inte är helt intuitivt, men det störa problemet är, att jag inte tror att den anvgränsar mellan gammla och nya requests. Detta innebär
att om jag får en request, parsar dens headers och gör något med datan, och sedan börjar bästa request när det fortfarande finns lite data kvar,  så kommer http header parsingen kajka.

Saker verkar ju för all dela fungera relativt bra, men koden som är här ger mig absolut inga garantier. Varje gång jag ska ändra koden för jag alltid en stor mängd arbete som fortfarande bygger på den gammla
skit metoden, så får se om jag tar det nu, men är definitivt något som krävs. 

Jag märker också att det har kommit en liten skillnad i filosofi i kod design sen projketet började. När jag först gjorde det här tyckte jag att få en std::string,byte buffer, som input till en http handler
var den största friheten man kunde få, absolut all information som behövs för att generera det perfekta svaret. Självklart var det här totalt ass. Detta innebär att koden som krävs för att parsa http 
datan duplikeras för varje handler, varje bugg relaterat till den överallt. Det gör också att verifiera integriten av requesten inte riktigt är möjligt, och på samma sätt, görs parallelt för varje 
handler. En relik från detta är att den råa requesten fortfarande finns med i HTTP handler kroppen, för att stödja gammal kod som inte dealade med HTTPRequest strukten. Detta är då något jag vill
helt gå bort ifrån.

En typ av funktionalitet som jag fortfarande inte riktigt vet hur jag vill abstrahera runt, är hur en handler kan skicka datan till clienten. Detta är nödvändigt för att implementera 
grejer som MBPM http handler. Det stora problemet är, att det inte riktigt går att göra mindre lågnivå. Min nuvarande tanke på att fixa detta, är genom att göra en distinktion mellan att skicka
en HTTP header, och att skicka body data, och eventuellt throwa exceptions om det görs i fel ordning. Detta gör att det i alla fall är uppenbart vad det är som krävs, även fast det fortfarnde 
är upp till den som skickar datan att se till att content-length blir rätt osv. Jag har funderat på om man ska kunna skicka en OctetInputStream också. Nackdelen är, att först och främst
så behöver man specificera headers innan ändå. Något annat negativt, är att det automatiskt blir chunked. Jag hatar att parsa chunked data. 

Men planen nu, fixa search parameters fast allt är brutet. Sedan när jag får ork att göra det bättre, prolly fixa Sockets interfacen så den blir enklare att jobba med, sedan fixa hur man får HTTP requesten,
och sedan, detta blir då väldigt ambitiöst, skriva om all MBWebsite kod att använda det nya interfacen samt det nya MBWebsite formatet. Det kan ta tid, men tror att det också kommer göra
hemsidan otroligt mycket enklare att uppehålla.